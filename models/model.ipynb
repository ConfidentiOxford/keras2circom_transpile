{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/train.zip"
      ],
      "metadata": {
        "id": "gryHrNH3Iyu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation"
      ],
      "metadata": {
        "id": "1ovPM6Hlvkig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/train'"
      ],
      "metadata": {
        "id": "yaUE5rTyrLnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    color_mode='rgb'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ezmv4X3osGv",
        "outputId": "69eab0d9-9966-4c13-a138-a37cbb1c9692"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 164 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "inputs = Input(shape=(28, 28, 3))\n",
        "x = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(2, activation='softmax')(x)  # Используем 2 выхода для 2 классов\n",
        "\n",
        "model = Model(inputs, x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aqGlz86osBL",
        "outputId": "126b11b9-ed96-459d-dbf4-0e427843f64a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 3)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 588)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                37696     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37826 (147.76 KB)\n",
            "Trainable params: 37826 (147.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "id": "JUdG7K5ksgVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation loss: {val_loss}, validation accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOhhTz2VsgTJ",
        "outputId": "8de31f70-8477-480e-b29a-1ec840038684"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.6250\n",
            "Validation loss: 0.6758458018302917, validation accuracy: 0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_rgb.h5')"
      ],
      "metadata": {
        "id": "GpX2ruX0sgQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I4RTSPGg2Oo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "test_image_path = '/content/vitalik.jpeg'\n",
        "img = load_img(test_image_path, target_size=(28, 28))\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "class_names = ['cat','dog']\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "print(f\"Predicted class: {predicted_class_name}\")"
      ],
      "metadata": {
        "id": "pXEYTX-lsgOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7c9070-5ed2-4319-8c56-08b22e1a323a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n",
            "Predicted class: dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U coremltools\n"
      ],
      "metadata": {
        "id": "H2NQf2rOsgLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "\n",
        "\n",
        "\n",
        "image_input = ct.ImageType(shape=(1, 28, 28, 3))\n",
        "\n",
        "\n",
        "\n",
        "coreml_model = ct.convert(\n",
        "    model,\n",
        "    inputs=[image_input],\n",
        "    classifier_config=ct.ClassifierConfig(['cat', 'dog']),\n",
        "    minimum_deployment_target=ct.target.iOS13\n",
        ")\n",
        "\n",
        "\n",
        "coreml_model.save('model_cat_dog_rgb.mlmodel')\n"
      ],
      "metadata": {
        "id": "6YUCjUUlor8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b25bf68-0090-4f17-a9f7-57cd4419e7ed"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:00<00:00, 20.06 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██████████| 15/15 [00:00<00:00, 2839.62 ops/s]\n",
            "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 5303.49 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 2187.56 passes/s]\n",
            "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 9/9 [00:00<00:00, 6800.35 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 19/19 [00:00<00:00, 3871.92 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "ly4ZGex0N7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/vitalik_resized_rgb.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "if image is None:\n",
        "    print(\"Не удалось загрузить изображение\")\n",
        "else:\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    height, width, channels = image.shape\n",
        "    print(\"Ширина изображения:\", width)\n",
        "    print(\"Высота изображения:\", height)\n",
        "    print(\"Количество каналов изображения:\", channels)\n"
      ],
      "metadata": {
        "id": "S8TY2bsZor5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "6baceb25-255e-4237-d708-ae1e36b4eb54"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ширина изображения: 28\n",
            "Высота изображения: 28\n",
            "Количество каналов изображения: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TJSS3dgor3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making input.json"
      ],
      "metadata": {
        "id": "aEXdJUN721hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json"
      ],
      "metadata": {
        "id": "lLm7FEZU3DBG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/vitalik_resized_rgb.jpeg'\n",
        "img = Image.open(img_path)"
      ],
      "metadata": {
        "id": "m7oruJaBorz4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dMDrfuJn7p_G"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "img_path = '/content/vitalik_resized_rgb.jpeg'\n",
        "img = Image.open(img_path)\n"
      ],
      "metadata": {
        "id": "ZRD3SVpH7q-y"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_matrix = np.array(img)\n"
      ],
      "metadata": {
        "id": "loofXaj37sSp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_matrix"
      ],
      "metadata": {
        "id": "JpUMnIKS7v3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = img_matrix / 255.0"
      ],
      "metadata": {
        "id": "SBCeeZcb7yrG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [[[int(x * float(10**18))] for x in row] for row in sample_input]\n",
        "\n"
      ],
      "metadata": {
        "id": "xGCkT-OB3IP3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0S3_Esf8ZN3",
        "outputId": "e7468c6a-3550-4442-ba40-3ab76c7aa8ba"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path for the output JSON file\n",
        "output_json_path = '/content/input.json'\n",
        "\n",
        "# Save the matrix in the required format as JSON with the key \"in\"\n",
        "with open(output_json_path, 'w') as f:\n",
        "    json.dump({\"in\": X}, f)\n"
      ],
      "metadata": {
        "id": "SCDjaJ5XorxK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Define the path of the image\n",
        "img_path = '/content/vitalik_resized_rgb.jpeg'\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "# Convert image to a numpy array\n",
        "img_array = np.array(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "X4v-MJua8wjL"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = img_array / 255.0"
      ],
      "metadata": {
        "id": "nNffkdlL9f98"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqwtnsPr9lzC",
        "outputId": "8e579c0d-a27a-4b53-a89a-a9e580ad941a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Convert the normalized pixel values to the required format\n",
        "# Ensuring each channel value of the pixel is wrapped in a list\n",
        "X = [[[int(channel_value * float(10**18)) for channel_value in pixel] for pixel in row] for row in sample_input]\n"
      ],
      "metadata": {
        "id": "HRmv7LBd9e33"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S35smT-j-FTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the path for the output JSON file\n",
        "output_json_path = '/content/input.json'\n",
        "\n",
        "# Save the matrix in the required format as JSON with the key \"in\"\n",
        "with open(output_json_path, 'w') as f:\n",
        "    json.dump({\"in\": X}, f)\n",
        "\n",
        "output_json_path\n"
      ],
      "metadata": {
        "id": "c90XZ96Joruc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef688e70-101a-4985-a200-ae94cd1db2ac"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/input.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_RYcts7orrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
